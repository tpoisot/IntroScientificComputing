<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Statistics on</title><link>https://sciencecomputing.io/packages/statistics/</link><description>Recent content in Statistics on</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://sciencecomputing.io/packages/statistics/index.xml" rel="self" type="application/rss+xml"/><item><title>Approximate Bayesian Computation</title><link>https://sciencecomputing.io/capstones/abc/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sciencecomputing.io/capstones/abc/</guid><description>Approximate Bayesian computation, or ABC for short, is a very useful heuristic to estimate the posterior distribution of model parameters, specifically when the analytical expression of the likelihood function is unavailable (or when we can&amp;rsquo;t be bothered to figure it out). The theory on how ABC works will not be covered here in detail, so reading the previous article (and the references it links to) is highly recommended.
We will rely on a few packages for this example:</description></item><item><title>Neural network with Flux</title><link>https://sciencecomputing.io/machinelearning/neural_network_flux/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sciencecomputing.io/machinelearning/neural_network_flux/</guid><description>In this lesson, we will create neural networks using Flux, a performant and elegant package for doing machine learning in Julia. Flux is very well documented, and multiple step-by-step examples have been written to provide users with a solid understanding of how it can be used to build machine learning models in a few lines of code only.
We will be using the seeds dataset, which we believe is a better version of the widely used iris dataset.</description></item><item><title>The flow of execution</title><link>https://sciencecomputing.io/lessons/control_flow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sciencecomputing.io/lessons/control_flow/</guid><description>Programming really is a language But if you understand three words, you will be able to hold a good conversation with your computer! These three words are if, for, and while. If you have some previous experience with writing code, you can skim through this lesson.
One great way to make your code robust is to keep it very simple, and one great way to keep your code very simple is to recognize that often, we want to do one of three things: do one thing if something happens (if), do one thing to a series of things (for), or do one thing until something happens (while).</description></item><item><title>Avoiding mistakes</title><link>https://sciencecomputing.io/lessons/avoiding_mistakes/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://sciencecomputing.io/lessons/avoiding_mistakes/</guid><description>We can&amp;rsquo;t avoid mistakes But we can work as cautiously as possible, to make sure we catch them in time. It is always better to try and fail to run something, than to have the operation keep going and accumulating mistakes.
There are four types of mistakes to look out for: mistakes in the code, confusing interface, issues with arguments, and lack of integration. Some are caused by the programmer, and some are caused by the user.</description></item></channel></rss>